{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-3.2.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('basics').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark.read.csv('Database/CardiovascularDisease/CVD_unclean.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+--------+-------------+-----------+------------+----------+--------+---------+------+------------+-----------+-----------+-----+---------------+-------------------+-----------------+----------------------------+-----------------------+\n",
      "|General_Health|             Checkup|Exercise|Heart_Disease|Skin_Cancer|Other_Cancer|Depression|Diabetes|Arthritis|   Sex|Age_Category|Height_(cm)|Weight_(kg)|  BMI|Smoking_History|Alcohol_Consumption|Fruit_Consumption|Green_Vegetables_Consumption|FriedPotato_Consumption|\n",
      "+--------------+--------------------+--------+-------------+-----------+------------+----------+--------+---------+------+------------+-----------+-----------+-----+---------------+-------------------+-----------------+----------------------------+-----------------------+\n",
      "|          Poor|Within the past 2...|      No|           No|         No|          No|        No|      No|      Yes|Female|       70-74|        150|      32.66|14.54|            Yes|                  0|               30|                          16|                     12|\n",
      "|     Very Good|Within the past year|      No|          Yes|         No|          No|        No|     Yes|       No|Female|       70-74|        165|      77.11|28.29|             No|                  0|               30|                           0|                      4|\n",
      "|     Very Good|Within the past year|     Yes|           No|         No|          No|        No|     Yes|       No|Female|       60-64|        163|      88.45|33.47|             No|                  4|               12|                           3|                     16|\n",
      "|          Poor|Within the past year|     Yes|          Yes|         No|          No|        No|     Yes|       No|  null|       75-79|        180|      93.44|28.73|             No|                  0|               30|                          30|                      8|\n",
      "|          Good|Within the past year|      No|           No|         No|          No|        No|      No|       No|  Male|         80+|        191|      88.45|24.37|            Yes|                  0|                8|                           4|                      0|\n",
      "+--------------+--------------------+--------+-------------+-----------+------------+----------+--------+---------+------+------------+-----------+-----------+-----+---------------+-------------------+-----------------+----------------------------+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "spark_df = spark_df.withColumn(\"Alcohol_Consumption\", col(\"Alcohol_Consumption\").cast(\"int\"))\n",
    "spark_df = spark_df.withColumn(\"Height_(cm)\", col(\"Height_(cm)\").cast(\"int\"))\n",
    "spark_df = spark_df.withColumn(\"Weight_(kg)\", col(\"Weight_(kg)\").cast(\"float\"))\n",
    "spark_df = spark_df.withColumn(\"BMI\", col(\"BMI\").cast(\"float\"))\n",
    "spark_df = spark_df.withColumn(\"Height_(cm)\", col(\"Height_(cm)\").cast(\"int\"))\n",
    "spark_df = spark_df.withColumn(\"Fruit_Consumption\", col(\"Fruit_Consumption\").cast(\"int\"))\n",
    "spark_df = spark_df.withColumn(\"Green_Vegetables_Consumption\", col(\"Green_Vegetables_Consumption\").cast(\"int\"))\n",
    "spark_df = spark_df.withColumn(\"FriedPotato_Consumption\", col(\"FriedPotato_Consumption\").cast(\"int\"))\n",
    "\n",
    "spark_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1780:>                                                       (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------+--------+-------------+-----------+------------+----------+--------+---------+---+------------+-----------+-----------+---+---------------+-------------------+-----------------+----------------------------+-----------------------+\n",
      "|General_Health|Checkup|Exercise|Heart_Disease|Skin_Cancer|Other_Cancer|Depression|Diabetes|Arthritis|Sex|Age_Category|Height_(cm)|Weight_(kg)|BMI|Smoking_History|Alcohol_Consumption|Fruit_Consumption|Green_Vegetables_Consumption|FriedPotato_Consumption|\n",
      "+--------------+-------+--------+-------------+-----------+------------+----------+--------+---------+---+------------+-----------+-----------+---+---------------+-------------------+-----------------+----------------------------+-----------------------+\n",
      "|             0|      0|       0|            0|          0|           0|         0|       0|        0|  0|           0|          0|          0|  0|              0|                  0|                0|                           0|                      0|\n",
      "+--------------+-------+--------+-------------+-----------+------------+----------+--------+---------+---+------------+-----------+-----------+---+---------------+-------------------+-----------------+----------------------------+-----------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum\n",
    "spark_cleaned_df = spark_df.na.drop()\n",
    "null_counts = spark_cleaned_df.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in spark_cleaned_df.columns])\n",
    "\n",
    "null_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+--------+-------------+-----------+------------+----------+--------+---------+------+------------+-----------+-----------+-----+---------------+-------------------+-----------------+----------------------------+-----------------------+-------------+--------------------------+------------------------+------------------------------+-----------------------------------+\n",
      "|General_Health|             Checkup|Exercise|Heart_Disease|Skin_Cancer|Other_Cancer|Depression|Diabetes|Arthritis|   Sex|Age_Category|Height_(cm)|Weight_(kg)|  BMI|Smoking_History|Alcohol_Consumption|Fruit_Consumption|Green_Vegetables_Consumption|FriedPotato_Consumption|Health_Status|Alcohol_Consumption_Status|Fruit_Consumption_Status|FriedPotato_Consumption_Status|Green_Vegetables_Consumption_Status|\n",
      "+--------------+--------------------+--------+-------------+-----------+------------+----------+--------+---------+------+------------+-----------+-----------+-----+---------------+-------------------+-----------------+----------------------------+-----------------------+-------------+--------------------------+------------------------+------------------------------+-----------------------------------+\n",
      "|          Poor|Within the past 2...|      No|           No|         No|          No|        No|      No|      Yes|Female|       70-74|        150|      32.66|14.54|            Yes|                  0|               30|                          16|                     12|  Underweight|      Zero Alcohol Cons...|    Low Fruit Consump...|          Low Fried Potato ...|               Low Green Vegetab...|\n",
      "|     Very Good|Within the past year|      No|          Yes|         No|          No|        No|     Yes|       No|Female|       70-74|        165|      77.11|28.29|             No|                  0|               30|                           0|                      4|   Overweight|      Zero Alcohol Cons...|    Low Fruit Consump...|          Low Fried Potato ...|               Zero Green Vegeta...|\n",
      "|     Very Good|Within the past year|     Yes|           No|         No|          No|        No|     Yes|       No|Female|       60-64|        163|      88.45|33.47|             No|                  4|               12|                           3|                     16|        Obese|      Low Alcohol Consu...|    Low Fruit Consump...|          Low Fried Potato ...|               Low Green Vegetab...|\n",
      "|          Good|Within the past year|      No|           No|         No|          No|        No|      No|       No|  Male|         80+|        191|      88.45|24.37|            Yes|                  0|                8|                           4|                      0|       Normal|      Zero Alcohol Cons...|    Low Fruit Consump...|          Zero Fried Potato...|               Low Green Vegetab...|\n",
      "|          Good|Within the past year|      No|           No|         No|          No|       Yes|      No|      Yes|  Male|       60-64|        183|     154.22|46.11|             No|                  0|               12|                          12|                     12|        Obese|      Zero Alcohol Cons...|    Low Fruit Consump...|          Low Fried Potato ...|               Low Green Vegetab...|\n",
      "+--------------+--------------------+--------+-------------+-----------+------------+----------+--------+---------+------+------------+-----------+-----------+-----+---------------+-------------------+-----------------+----------------------------+-----------------------+-------------+--------------------------+------------------------+------------------------------+-----------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "# Construct the Health_Status\n",
    "spark_cleaned_constructed_df = spark_cleaned_df.withColumn(\n",
    "  'Health_Status',\n",
    "  when(col('BMI') < 18.5, \"Underweight\")\n",
    "  .when((col('BMI') >= 18.5) & (col('BMI') <= 24.9), \"Normal\")\n",
    "  .when((col('BMI') >= 25) & (col('BMI') <= 29.9), \"Overweight\")\n",
    "  .otherwise(\"Obese\")\n",
    ")\n",
    "\n",
    "\n",
    "# Construct the Alcohol_Consumption_Status\n",
    "spark_cleaned_constructed_df = spark_cleaned_constructed_df.withColumn(\n",
    "  'Alcohol_Consumption_Status',\n",
    "  when(col('Alcohol_Consumption') == 0 , \"Zero Alcohol Consumption\")\n",
    "  .when(col('Alcohol_Consumption') <= 7.5 , \"Low Alcohol Consumption\")\n",
    "  .when((col('Alcohol_Consumption') > 7.5) & (col('Alcohol_Consumption') <= 15),\"Medium Alcohol Consumption\")\n",
    "  .when((col('Alcohol_Consumption') > 15) & (col('Alcohol_Consumption') <= 22.5), \"High Alcohol Consumption\")\n",
    "  .otherwise(\"Excess Alcohol Consumption\")\n",
    ")\n",
    "\n",
    "# Construct the Fruit_Consumption_Status\n",
    "spark_cleaned_constructed_df = spark_cleaned_constructed_df.withColumn(\n",
    "  'Fruit_Consumption_Status',\n",
    "  when(col('Fruit_Consumption') == 0 , \"Zero Fruit Consumption\")\n",
    "  .when(col('Fruit_Consumption') <= 30 , \"Low Fruit Consumption\")\n",
    "  .when((col('Fruit_Consumption') > 30) & (col('Fruit_Consumption') <= 60),\"Medium Fruit Consumption\")\n",
    "  .when((col('Fruit_Consumption') > 60) & (col('Fruit_Consumption') <= 90), \"High Fruit Consumption\")\n",
    "  .otherwise(\"Excess Fruit Consumption\")\n",
    ")\n",
    "\n",
    "# Construct the FriedPotato_Consumption_Status\n",
    "spark_cleaned_constructed_df = spark_cleaned_constructed_df.withColumn(\n",
    "  'FriedPotato_Consumption_Status',\n",
    "  when(col('FriedPotato_Consumption') == 0 , \"Zero Fried Potato Consumption\")\n",
    "  .when(col('FriedPotato_Consumption') <= 30 , \"Low Fried Potato Consumption\")\n",
    "  .when((col('FriedPotato_Consumption') > 30) & (col('FriedPotato_Consumption') <= 60),\"Medium Fried Potato Consumption\")\n",
    "  .when((col('FriedPotato_Consumption') > 60) & (col('FriedPotato_Consumption') <= 90), \"High Fried Potato Consumption\")\n",
    "  .otherwise(\"Excess Fried Potato Consumption\")\n",
    ")\n",
    "\n",
    "# Construct the Green_Vegetables_Consumption_Status\n",
    "spark_cleaned_constructed_df = spark_cleaned_constructed_df.withColumn(\n",
    "  'Green_Vegetables_Consumption_Status',\n",
    "  when(col('Green_Vegetables_Consumption') == 0 , \"Zero Green Vegetable Consumption\")\n",
    "  .when(col('Green_Vegetables_Consumption') <= 30 , \"Low Green Vegetable Consumption\")\n",
    "  .when((col('Green_Vegetables_Consumption') > 30) & (col('Green_Vegetables_Consumption') <= 60),\"Medium Green Vegetable Consumption\")\n",
    "  .when((col('Green_Vegetables_Consumption') > 60) & (col('Green_Vegetables_Consumption') <= 90), \"High Green Vegetable Consumption\")\n",
    "  .otherwise(\"Excess Green Vegetable Consumption\")\n",
    ")\n",
    "\n",
    "spark_cleaned_constructed_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+--------+-------------+-----------+------------+----------+--------+---------+------+------------+---------------+-------------+--------------------------+------------------------+------------------------------+-----------------------------------+\n",
      "|General_Health|             Checkup|Exercise|Heart_Disease|Skin_Cancer|Other_Cancer|Depression|Diabetes|Arthritis|   Sex|Age_Category|Smoking_History|Health_Status|Alcohol_Consumption_Status|Fruit_Consumption_Status|FriedPotato_Consumption_Status|Green_Vegetables_Consumption_Status|\n",
      "+--------------+--------------------+--------+-------------+-----------+------------+----------+--------+---------+------+------------+---------------+-------------+--------------------------+------------------------+------------------------------+-----------------------------------+\n",
      "|          Poor|Within the past 2...|      No|           No|         No|          No|        No|      No|      Yes|Female|       70-74|            Yes|  Underweight|      Zero Alcohol Cons...|    Low Fruit Consump...|          Low Fried Potato ...|               Low Green Vegetab...|\n",
      "|     Very Good|Within the past year|      No|          Yes|         No|          No|        No|     Yes|       No|Female|       70-74|             No|   Overweight|      Zero Alcohol Cons...|    Low Fruit Consump...|          Low Fried Potato ...|               Zero Green Vegeta...|\n",
      "|     Very Good|Within the past year|     Yes|           No|         No|          No|        No|     Yes|       No|Female|       60-64|             No|        Obese|      Low Alcohol Consu...|    Low Fruit Consump...|          Low Fried Potato ...|               Low Green Vegetab...|\n",
      "|          Good|Within the past year|      No|           No|         No|          No|        No|      No|       No|  Male|         80+|            Yes|       Normal|      Zero Alcohol Cons...|    Low Fruit Consump...|          Zero Fried Potato...|               Low Green Vegetab...|\n",
      "|          Good|Within the past year|      No|           No|         No|          No|       Yes|      No|      Yes|  Male|       60-64|             No|        Obese|      Zero Alcohol Cons...|    Low Fruit Consump...|          Low Fried Potato ...|               Low Green Vegetab...|\n",
      "+--------------+--------------------+--------+-------------+-----------+------------+----------+--------+---------+------+------------+---------------+-------------+--------------------------+------------------------+------------------------------+-----------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop useless variable\n",
    "\n",
    "# BMI is better than weight and height\n",
    "spark_cleaned_constructed_df = spark_cleaned_constructed_df.drop(col('Weight_(kg)'))\n",
    "spark_cleaned_constructed_df = spark_cleaned_constructed_df.drop(col('Height_(cm)'))\n",
    "\n",
    "spark_cleaned_constructed_df = spark_cleaned_constructed_df.drop(col('Alcohol_Consumption'))\n",
    "spark_cleaned_constructed_df = spark_cleaned_constructed_df.drop(col('BMI'))\n",
    "spark_cleaned_constructed_df = spark_cleaned_constructed_df.drop(col('Fruit_Consumption'))\n",
    "spark_cleaned_constructed_df = spark_cleaned_constructed_df.drop(col('FriedPotato_Consumption'))\n",
    "spark_cleaned_constructed_df = spark_cleaned_constructed_df.drop(col('Green_Vegetables_Consumption'))\n",
    "\n",
    "spark_cleaned_constructed_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Heart_Disease'>"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# under-sampling method \n",
    "count_class_0 = spark_cleaned_constructed_df.filter(spark_cleaned_constructed_df['Heart_Disease'] == \"Yes\").count()\n",
    "count_class_1 = spark_cleaned_constructed_df.filter(spark_cleaned_constructed_df['Heart_Disease'] == \"No\").count()\n",
    "\n",
    "\n",
    "fraction = count_class_0 / float(count_class_1)\n",
    "df_class_1_under = spark_cleaned_constructed_df.filter(spark_cleaned_constructed_df['Heart_Disease'] == \"No\").sample(False, fraction)\n",
    "df_balanced = df_class_1_under.unionAll(spark_cleaned_constructed_df.filter(spark_cleaned_constructed_df['Heart_Disease'] == \"Yes\"))\n",
    "\n",
    "df_balanced_pandas = df_balanced.toPandas()\n",
    "df_balanced_pandas['Heart_Disease'].value_counts().plot.pie()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_balanced = df_balanced.withColumn(\"Heart_Disease\", \n",
    "                   when(col(\"Heart_Disease\") == \"Yes\", 1)\n",
    "                   .when(col(\"Heart_Disease\") == \"No\", 0)\n",
    "                   .cast('int')\n",
    "                   )\n",
    "\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(df_balanced) for column in df_balanced.columns]\n",
    "encoders = [OneHotEncoder(inputCol=column+\"_index\", outputCol=column+\"_vec\") for column in df_balanced.columns]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders], outputCol=\"features\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "categorical_columns = [i for i in df_balanced.columns if i != \"Heart_Disease\"]\n",
    "log_reg = LogisticRegression(featuresCol='features', labelCol='Heart_Disease')\n",
    "pipeline = Pipeline(stages=indexers + encoders + [assembler, log_reg])\n",
    "\n",
    "train_data, test_data = df_balanced.randomSplit([0.7,.3])\n",
    "fit_model = pipeline.fit(train_data)\n",
    "results = fit_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy:  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy:  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7510\n",
      "           1       1.00      1.00      1.00      7455\n",
      "\n",
      "    accuracy                           1.00     14965\n",
      "   macro avg       1.00      1.00      1.00     14965\n",
      "weighted avg       1.00      1.00      1.00     14965\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Heart_Disease\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "train_results = fit_model.transform(train_data)\n",
    "train_accuracy = evaluator.evaluate(train_results)\n",
    "\n",
    "\n",
    "print(\"Train set accuracy: \", train_accuracy)\n",
    "test_accuracy = evaluator.evaluate(results)\n",
    "print(\"Test set accuracy: \", test_accuracy)\n",
    "\n",
    "\n",
    "# convert to Pandas DataFrame\n",
    "y_true = results.select(\"Heart_Disease\").toPandas()\n",
    "y_pred = results.select(\"prediction\").toPandas()\n",
    "\n",
    "# use classification_report from scikit-learn to generate report.\n",
    "print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC curve: 0.9999998035259939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n",
      "[Stage 1887:>                                                       (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "# 8.4 evaluate model \n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Evaluate model\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"Heart_Disease\")\n",
    "roc_auc = evaluator.evaluate(results, {evaluator.metricName: \"areaUnderROC\"})\n",
    "print(f\"Area under ROC curve: {roc_auc}\")\n",
    "\n",
    "# Get FPR and TPR\n",
    "results_rdd = results.select(['probability', 'Heart_Disease']) \\\n",
    "    .rdd.map(lambda row: (float(row['probability'][1]), float(row['Heart_Disease'])))\n",
    "metrics = BinaryClassificationMetrics(results_rdd)\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "y_test = results.select('Heart_Disease').rdd.flatMap(lambda x: x).collect()\n",
    "y_score = results.select('probability').rdd.map(lambda x: x['probability'][1]).collect()\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# drow ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Logistic Regression ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['General_Health',\n",
       " 'Checkup',\n",
       " 'Exercise',\n",
       " 'Heart_Disease',\n",
       " 'Skin_Cancer',\n",
       " 'Other_Cancer',\n",
       " 'Depression',\n",
       " 'Diabetes',\n",
       " 'Arthritis',\n",
       " 'Sex',\n",
       " 'Age_Category',\n",
       " 'Smoking_History',\n",
       " 'Health_Status',\n",
       " 'Alcohol_Consumption_Status',\n",
       " 'Fruit_Consumption_Status',\n",
       " 'FriedPotato_Consumption_Status',\n",
       " 'Green_Vegetables_Consumption_Status']"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n",
      "[Stage 1766:==========================================>             (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+------------------+------------------+-------------------+\n",
      "| antecedent|          consequent|        confidence|              lift|            support|\n",
      "+-----------+--------------------+------------------+------------------+-------------------+\n",
      "|[Obese, No]|                 [1]|0.5441711004583047|1.0874048768772044|0.20707627543349705|\n",
      "|[Obese, No]|[Low Green Vegeta...|0.8920086393088553|1.0060558664237451| 0.3394407136413752|\n",
      "|[Obese, No]|[Low Fruit Consum...|0.7716904598851604| 1.027787440698738|0.29365540743710533|\n",
      "|[Obese, No]|[Low Fried Potato...|0.8529737133224464|1.0262057131268145|0.32458654906284456|\n",
      "|[Obese, No]|[Zero Alcohol Con...|0.5620818627192752|1.0828970656838157|0.21389195148842338|\n",
      "+-----------+--------------------+------------------+------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.fpm import FPGrowth\n",
    "from pyspark.sql.functions import array, array_distinct\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "df_as_list = df_balanced.withColumn(\"items\", array(\n",
    " df_balanced.columns\n",
    "  ))\n",
    "# Remove duplicates from the array\n",
    "df_as_list = df_as_list.withColumn(\"items\", array_distinct(\"items\"))\n",
    "\n",
    "df_as_list = df_as_list.select(\"items\")\n",
    "\n",
    "fpGrowth = FPGrowth(itemsCol=\"items\", minSupport=0.1, minConfidence=0.5)\n",
    "\n",
    "model = fpGrowth.fit(df_as_list)\n",
    "\n",
    "model.associationRules.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+------------------+------------------+-------------------+\n",
      "|          antecedent|consequent|        confidence|              lift|            support|\n",
      "+--------------------+----------+------------------+------------------+-------------------+\n",
      "|[Fair, Within the...|       [1]|0.7501408450704226|1.4989895872591745|0.10676556078981658|\n",
      "|[Fair, Within the...|       [1]|0.7501054111033029|1.4989187803592479|0.10698606795629949|\n",
      "|[Fair, Within the...|       [1]|0.7472191663610805|1.4931512623747198|0.12254184624636665|\n",
      "|[Fair, Within the...|       [1]|0.7472137170851194|1.4931403732090684|0.12230129297383983|\n",
      "|[Fair, Within the...|       [1]| 0.746241897669287|1.4911984083172722|0.10846947980354817|\n",
      "+--------------------+----------+------------------+------------------+-------------------+\n",
      "\n",
      "+--------------------+----------+------------------+------------------+-------------------+\n",
      "|          antecedent|consequent|        confidence|              lift|            support|\n",
      "+--------------------+----------+------------------+------------------+-------------------+\n",
      "|[Very Good, Low F...|       [0]|0.6709209209209209|1.3429994839749666|0.16123083091109552|\n",
      "|[Very Good, Low F...|       [0]|0.6708090075062552|1.3427754640443619|0.16123083091109552|\n",
      "|[Very Good, Low F...|       [0]|0.6662973631730557|1.3337443907502862|0.12055728174802045|\n",
      "|[Very Good, Low F...|       [0]|0.6661497563136908|1.3334489223429424|0.12055728174802045|\n",
      "|[Very Good, Low F...|       [0]|0.6657737838071373|1.3326963286071603|  0.154455247068257|\n",
      "+--------------------+----------+------------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import array, desc\n",
    "\n",
    "filtered_rules_1 = model.associationRules.filter(F.expr(\"array_contains(consequent, '1')\")).orderBy(desc(\"confidence\")).limit(5)\n",
    "filtered_rules_1.show()\n",
    "filtered_rules_0 = model.associationRules.filter(F.expr(\"array_contains(consequent, '0')\")).orderBy(desc(\"confidence\")).limit(5)\n",
    "filtered_rules_0.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
